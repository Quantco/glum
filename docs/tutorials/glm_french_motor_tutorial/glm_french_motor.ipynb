{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLM Tutorial: French Motor Third-Party Liability Claims\n",
    "\n",
    "\n",
    "#### Intro\n",
    "This tutorial shows why and how to use Poisson, Gamma, and Tweedie GLMs on an insurance claims dataset using `quantcore.glm` It was inspired by, and closely mirrors, two other GLM tutorials that used this dataset:\n",
    "1. An sklearn-learn tutorial, [Tweedie regression on insurance claims](https://scikit-learn.org/stable/auto_examples/linear_model/plot_tweedie_regression_insurance_claims.html#pure-premium-modeling-via-a-product-model-vs-single-tweedieregressor), which was created for this (partially merged) [sklearn PR](https://github.com/scikit-learn/scikit-learn/pull/9405)\n",
    "2. An R tutorial, [Case Study: French Motor Third-Party Liability Claims](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3164764) with [R code](https://github.com/JSchelldorfer/ActuarialDataScience/tree/master/1%20-%20French%20Motor%20Third-Party%20Liability%20Claims).\n",
    "\n",
    "\n",
    "#### Background\n",
    "Insurance claims are requests made by a policy holder to an insurance company for compensation in the event of a covered loss. When modeling these claims, the goal is often to estimate, per policy, the total claim amount per exposure unit. (i.e. number of claims $\\times$ average amount per claim, per year). This amount is also referred to as the pure premium.\n",
    "\n",
    "Two approaches for modeling this value are:\n",
    "1. Modeling the total claim amount per exposure directly\n",
    "2. Modeling number of claims and claim amount separately with a frequency and a severity model\n",
    "\n",
    "In this tutorial, we demonstrate both approaches. We start with the second option as it shows how to use two different families/distributions (Poisson and Gamma) within a GLM on a single dataset. We then show the first approach using a single poison-gamma Tweedie regressor (i.e. a Tweedie with power $p \\in (1,2)$)\n",
    "\n",
    "\n",
    "#### Why not OLS?:\n",
    "\n",
    "TLDR: The world is not Normal!\n",
    "\n",
    "If we fit a GLM, the mean-variance relation of its family=distribution is key. Specifying a family is assuming its mean-variance relationship, which tells the GLM, how much a difference in predicted vs observed target values accounts to how much difference in (estimated parameters of) features. For example, the squared error&mdash;Normal distribution&mdash;is quite famous for being very sensitive to outliers, because it attributes much weight to large deviations. Simply put and slightly overstated: With a Normal distribution, a single large claim amount of only one young driver could result in a high prediction for all young drivers.\n",
    "\n",
    "## Table of Contents <a class=\"anchor\" id=\"toc\"></a>\n",
    "* [1. Load and Prepare Datasets from Openml.org](#1-load)\n",
    "* [2. Frequency GLM - Poisson Distribution](#2-frequency)\n",
    "* [3. Severity GLM - Gamma Distribution](#3-severity)\n",
    "* [4. Combined GLM - Tweedie Distribution](#4-combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as optimize\n",
    "import scipy.stats\n",
    "from dask_ml.preprocessing import Categorizer\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from quantcore.glm import GeneralizedLinearRegressor\n",
    "from quantcore.glm import TweedieDistribution\n",
    "\n",
    "from load_transform import load_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Datasets from Openml.org <a class=\"anchor\" id=\"1-load\"></a>\n",
    "[back to table of contents](#toc)\n",
    "\n",
    "First, we load in our dataset from openML and apply several transformations. In the interest of simplicity, we do not include the data loading and preparation code in this notebook. Below is a list of further resources if you wish to explore further: \n",
    "1. If you want to run the same code yourself, please see the helper functions here: **TODO – include link once in master**. \n",
    "2. For a detailed description of the data, see http://dutangc.free.fr/pub/RRepos/web/CASdatasets-index.html.\n",
    "3. For an excellent exploratory data analysis, see the case study paper.\n",
    "\n",
    "Some important notes about the dataset post-transformation:\n",
    "- Total claim amounts are aggregated per policy\n",
    "- For ClaimAmountCut, the claim amounts (pre-aggregation) were cut at 100,000 per single claim. We choose to use this amount rather than the raw ClaimAmount. (100,000 is the 0.9984 quantile but claims > 100,000 account for 25% of the overall claim amount)\n",
    "- We aggregate the total claim amounts per policy\n",
    "* ClaimNb is the total number of claims per policy, and ClaimNb_pos as the claim number with claim amount greater zero\n",
    "* VehPower, VehAge, and DrivAge are clipped and/or digitized into bins so that they can be used as categoricals later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClaimNb</th>\n",
       "      <th>Exposure</th>\n",
       "      <th>Area</th>\n",
       "      <th>VehPower</th>\n",
       "      <th>VehAge</th>\n",
       "      <th>DrivAge</th>\n",
       "      <th>BonusMalus</th>\n",
       "      <th>VehBrand</th>\n",
       "      <th>VehGas</th>\n",
       "      <th>Density</th>\n",
       "      <th>Region</th>\n",
       "      <th>ClaimAmount</th>\n",
       "      <th>ClaimAmountCut</th>\n",
       "      <th>ClaimNb_pos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IDpol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>D</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1217</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.77000</td>\n",
       "      <td>D</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>1217</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>B</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>54</td>\n",
       "      <td>R22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.09000</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>76</td>\n",
       "      <td>R72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.84000</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>76</td>\n",
       "      <td>R72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114326</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00274</td>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>3317</td>\n",
       "      <td>R93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114327</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00274</td>\n",
       "      <td>E</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>9850</td>\n",
       "      <td>R11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114328</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00274</td>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>1323</td>\n",
       "      <td>R82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114329</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00274</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>B12</td>\n",
       "      <td>Regular</td>\n",
       "      <td>95</td>\n",
       "      <td>R26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114330</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00274</td>\n",
       "      <td>B</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>B12</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>65</td>\n",
       "      <td>R72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>678013 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ClaimNb  Exposure Area  VehPower  VehAge  DrivAge  BonusMalus  \\\n",
       "IDpol                                                                    \n",
       "1              1   0.10000    D         5       0        5          50   \n",
       "3              1   0.77000    D         5       0        5          50   \n",
       "5              1   0.75000    B         6       1        5          50   \n",
       "10             1   0.09000    B         7       0        4          50   \n",
       "11             1   0.84000    B         7       0        4          50   \n",
       "...          ...       ...  ...       ...     ...      ...         ...   \n",
       "6114326        0   0.00274    E         4       0        5          50   \n",
       "6114327        0   0.00274    E         4       0        4          95   \n",
       "6114328        0   0.00274    D         6       1        4          50   \n",
       "6114329        0   0.00274    B         4       0        5          50   \n",
       "6114330        0   0.00274    B         7       1        2          54   \n",
       "\n",
       "        VehBrand   VehGas  Density Region  ClaimAmount  ClaimAmountCut  \\\n",
       "IDpol                                                                    \n",
       "1            B12  Regular     1217    R82          0.0             0.0   \n",
       "3            B12  Regular     1217    R82          0.0             0.0   \n",
       "5            B12   Diesel       54    R22          0.0             0.0   \n",
       "10           B12   Diesel       76    R72          0.0             0.0   \n",
       "11           B12   Diesel       76    R72          0.0             0.0   \n",
       "...          ...      ...      ...    ...          ...             ...   \n",
       "6114326      B12  Regular     3317    R93          0.0             0.0   \n",
       "6114327      B12  Regular     9850    R11          0.0             0.0   \n",
       "6114328      B12   Diesel     1323    R82          0.0             0.0   \n",
       "6114329      B12  Regular       95    R26          0.0             0.0   \n",
       "6114330      B12   Diesel       65    R72          0.0             0.0   \n",
       "\n",
       "         ClaimNb_pos  \n",
       "IDpol                 \n",
       "1                  0  \n",
       "3                  0  \n",
       "5                  0  \n",
       "10                 0  \n",
       "11                 0  \n",
       "...              ...  \n",
       "6114326            0  \n",
       "6114327            0  \n",
       "6114328            0  \n",
       "6114329            0  \n",
       "6114330            0  \n",
       "\n",
       "[678013 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = load_transform()\n",
    "with pd.option_context('display.max_rows', 10):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Frequency GLM - Poisson Distribution <a class=\"anchor\" id=\"2-frequency\"></a>\n",
    "[back to Table of Contents](#toc)\n",
    "\n",
    "We start with the first part of our two part GLM - modeling the frequency of claims using a Poisson regression. Below, we give some background on why the Poisson family makes the most sense in this context.\n",
    "\n",
    "### 2.1 Why Poisson distributions?\n",
    "We define:\n",
    "- $z$: number of claims\n",
    "- $w$: exposure (time in years under risk)\n",
    "- $y = \\frac{z}{w}$: claim frequency per year\n",
    "- $X$: feature matrix\n",
    "\n",
    "Note that both the number of claims $z$ and the exposure $w$ are additive. This way, the frequency behaves as expected, if we calculate averages: $\\mathrm{mean}(y) = \\frac{1}{\\sum_i w_i}\\sum_i w_i y_i = \\frac{\\sum_i z_i}{\\sum_i w_i}$.\n",
    "\n",
    "The number of claims $z$ is an integer, $z \\in [0, 1, 2, 3, \\ldots]$. Theoretically, a policy could have an arbitrarily large number of claims&mdash;very unlikely but possible. The simplest distribution for this range is a Poisson distribution $z \\sim Poisson$. Instead of $z$, we will model the frequency $y$, which is still (scaled) Poisson distributed with variance inverse proportional to $w$, cf. [wikipedia:Reproductive_EDM](https://en.wikipedia.org/wiki/Exponential_dispersion_model#Reproductive). A very important property of the Poisson distribution is its mean-variance relation: The variance is proportional to the mean.\n",
    "\n",
    "We summarize our assumptions for a Poisson-GLM model with log-link:\n",
    "- target: $y \\sim Poisson$\n",
    "- mean: $\\mathrm{E}[y] = \\exp(X\\beta)$\n",
    "- variance: $\\mathrm{Var}[y] = \\frac{1}{w} \\mathrm{E}[y]$\n",
    "\n",
    "*Note*: We don't need $y$ to be Poisson distributed, for the purpose of estimating the expecation value. Just the mean-variance relationship should be approximately fulfilled: $\\mathrm{Var}[y] \\propto \\frac{1}{w} \\mathrm{E}[y]$.\n",
    "\n",
    "To verify our assumptions, we start by plotting the observed frequencies and a fitted Poisson distributions (Poisson regression with intercept only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_plot = (\n",
    "    df.loc[:, ['ClaimNb', 'Exposure']].groupby('ClaimNb').sum()\n",
    "    .assign(Frequency_Observed = lambda x: x.Exposure / df['Exposure'].sum())\n",
    ")\n",
    "\n",
    "df_plot['Frequency_Observed'].plot(kind = 'bar', label='observed')\n",
    "\n",
    "mean = df['ClaimNb'].sum() / df['Exposure'].sum()\n",
    "x = range(5)\n",
    "plt.plot(x, scipy.stats.poisson.pmf(x, mean), 'ro', ms=8, mec='r', label='Poisson fit')\n",
    "plt.vlines(x=x, ymin=0, ymax=scipy.stats.poisson.pmf(x, mean), color='r', lw=4)\n",
    "plt.xticks(x)\n",
    "plt.legend()\n",
    "plt.title(\"Frequency\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad, visually.\n",
    "\n",
    "Next, we want to check the mean-variance relationship of the Poisson distribution: $\\mathrm{Var}[Y] = \\frac{\\mathrm{E}[Y]}{Exposure}$. To do so, we choose the feature `VehPower`, because we hope that the frequency $Y$ depends very much on it. We then plot empirical estimates of $\\mathrm{Var}[Y]$ vs $\\mathrm{E}[Y]/Exposure$ for every value of `VehPower`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check mean-variance relationship for Poisson: Var[Y] = E[Y] / Exposure\n",
    "# Estimate Var[Y] and E[Y]\n",
    "# Plot estimates Var[Y] vs E[Y]/Exposure\n",
    "# Note: We group by VehPower in order to have different E[Y].\n",
    "\n",
    "def my_agg(x):\n",
    "    \"\"\"See https://stackoverflow.com/q/44635626\"\"\"\n",
    "    x_freq = x['Freq']\n",
    "    x_expos = x['Exposure']\n",
    "    n = x_freq.shape[0]\n",
    "    names = {\n",
    "        'Freq_mean': np.average(x_freq, weights=x_expos),\n",
    "        'Freq_var': 1/(n-1) * np.sum((x_expos/np.sum(x_expos)) * (x_freq-np.average(x_freq, weights=x_expos))**2),\n",
    "        'Exposure_sum': x_expos.sum()\n",
    "    }\n",
    "    return pd.Series(names, index=['Freq_mean', 'Freq_var', 'Exposure_sum'])\n",
    "\n",
    "df_plot = df.assign(Freq = lambda x: x['ClaimNb']/x['Exposure']).groupby('VehPower').apply(my_agg)\n",
    "\n",
    "plt.plot(df_plot['Freq_mean']/df_plot['Exposure_sum'], df_plot['Freq_var'], '.',\n",
    "         markersize=12, label='observed')\n",
    "\n",
    "plt.plot([(df_plot['Freq_mean']/df_plot['Exposure_sum']).min(),\n",
    "          (df_plot['Freq_mean']/df_plot['Exposure_sum']).max()],\n",
    "         [df_plot['Freq_var'].min(), df_plot['Freq_var'].max()],\n",
    "         'k--', label='45° line')\n",
    "\n",
    "plt.xlabel('Mean of Frequency / Exposure ')\n",
    "plt.ylabel('Variance of Frequency')\n",
    "plt.title('Man-Variance of Claim Frequency by VehPower');\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a strong confirmation for the use of a Poisson when fitting!\n",
    "\n",
    "*Hints*:\n",
    "- If Y were normal distributed, one should see a horizontal line, because for a Normal: Var[Y] ~ constant/Exposure.\n",
    "- The 45° line is not even necessary, any straight line through the origin would be enough for simple reasons:\n",
    "    1. A quasi-Poisson distribution has $Var[Y] = \\phi * E[Y]/w$ for some $\\phi$.\n",
    "    2. $\\phi$ does not influence the estimation/fitting of E[Y] (thanks @[ExponentialDispersionFamily](https://en.wikipedia.org/wiki/Exponential_dispersion_model))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train and Test Frequency GLM\n",
    "\n",
    "\n",
    "We now start fitting our model. We use claim number with positive claim amount 'ClaimNb_pos' and we devide the dataset into training set and test set with a 9:1 random split. \n",
    "\n",
    "Also, notice that we do not one hot encode our columns. Rather, we take advantage of `quantcore.glm`'s integration with `quantcore.matrix`, which allows us to pass in categorical columns directly! `quantcore.matrix` will handle the encoding for us and even includes a handful of helpful matrix operation optimizations. We use the `Categorizer` from [dask_ml](https://ml.dask.org/modules/generated/dask_ml.preprocessing.Categorizer.html) to set our categorical columns as categorical dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = df['ClaimNb_pos'].values\n",
    "weight = df['Exposure'].values\n",
    "y = z / weight # claims frequency\n",
    "\n",
    "ss = ShuffleSplit(n_splits=1, test_size=0.1, random_state=42)\n",
    "train, test = next(ss.split(y))\n",
    "\n",
    "categoricals = [\"VehBrand\", \"VehGas\", \"Region\", \"Area\", \"DrivAge\", \"VehAge\", \"VehPower\"]\n",
    "predictors = categoricals + [\"BonusMalus\", \"Density\"]\n",
    "glm_categorizer = Categorizer(columns=categoricals)\n",
    "\n",
    "X_train_p = glm_categorizer.fit_transform(df[predictors].iloc[train])\n",
    "X_test_p = glm_categorizer.fit_transform(df[predictors].iloc[test])\n",
    "y_train_p, y_test_p = y[train], y[test] \n",
    "w_train_p, w_test_p = weight[train], weight[test]\n",
    "z_train_p, z_test_p = z[train], z[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define our GLM using the `GeneralizedLinearRegressor` class from `quantcore.glm`.\n",
    "- `family='poisson'`: creates a Poisson regressor\n",
    "- `alpha_search=True`: tells the GLM to search along the regularization path for the best alpha\n",
    "- `l1_ratio = 1` tells the GLM to only use l1 penalty (not l2). `l1_ratio` is the elastic net mixing parameter. For ``l1_ratio = 0``, the penalty is an L2 penalty. ``For l1_ratio = 1``, it is an L1 penalty.  For ``0 < l1_ratio < 1``, the penalty is a combination of L1 and L2.\n",
    "\n",
    "See the `GeneralizedLinearRegressor` class documentation for more details (TODO: include documentation link once up).\n",
    "\n",
    "*Note*: `quantcore.glm` also supported a cross validation model GeneralizedLinearRegressorCV. However, like most cross validation models, it is inevitably slower, so we don't demonstrate it in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_glm1 = GeneralizedLinearRegressor(family='poisson', alpha_search=True, l1_ratio=1, fit_intercept=True)\n",
    "\n",
    "f_glm1.fit(\n",
    "    X_train_p,\n",
    "    y_train_p,\n",
    "    sample_weight=w_train_p\n",
    ");\n",
    "\n",
    "pd.DataFrame({'coefficient': np.concatenate(([f_glm1.intercept_], f_glm1.coef_))},\n",
    "             index=['intercept'] + f_glm1.feature_names_).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure our model's test and train performance, we use the deviance function for the Poisson family. We can get the total deviance function directly from `quantcore.glm`'s distribution classes and divide it by the sum of our sample weight. \n",
    "\n",
    "*Note*: a Poisson distribution is equivlane to a Tweedie distribution with power = 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PoissonDist = TweedieDistribution(1)\n",
    "print('training loss f_glm1: {}'.format(\n",
    "    PoissonDist.deviance(y_train_p, f_glm1.predict(X_train_p), weights=w_train_p)/np.sum(w_train_p)\n",
    "))\n",
    "\n",
    "print('test loss f_glm1: {}'.format(\n",
    "      PoissonDist.deviance(y_test_p, f_glm1.predict(X_test_p), weights=w_test_p)/np.sum(w_test_p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GLM with canonical link function (Normal - identity, Poisson - log, Gamma - 1/x, Binomial - logit) with an intercept term has the so called **balance property**. Neglecting small deviations by the opimizer used for fitting, the results fulfil on the training sample:\n",
    "$$\\sum_{i \\in training} w_i y_i = \\sum_{i \\in training} w_i \\hat{\\mu}_i$$\n",
    "Summing up the predictions $\\hat{\\mu}_i$ yields exaclty the observations $y_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance property of GLM with canonical link, like log-link for Poisson:\n",
    "z_train_p.sum(), (f_glm1.predict(X_train_p) * w_train_p).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Poisson deviance, note that the following are equivalent (with freq = count/weight)\n",
    "# dev(observed count, predicted count) ~ dev(observed freq, predicted freq, sample_weight=weight)\n",
    "print('training loss f_glm1: {}'.format(\n",
    "    PoissonDist.deviance(y_train_p, f_glm1.predict(X_train_p), weights=w_train_p)/len(train)))\n",
    "\n",
    "print('training loss f_glm1: {}'.format(\n",
    "    PoissonDist.deviance(z_train_p, f_glm1.predict(X_train_p) * w_train_p)/len(train)))\n",
    "\n",
    "print('testing loss f_glm1:  {}'.format(\n",
    "    PoissonDist.deviance(z_test_p, f_glm1.predict(X_test_p) * w_test_p)/len(test)))\n",
    "\n",
    "# Compare to test loss of Mean model\n",
    "print('testing loss Mean:    {}'.format(\n",
    "    PoissonDist.deviance(z_test_p,\n",
    "                     np.average(y_train_p, weights=w_train_p)*w_test_p)/len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Severity GLM -  Gamma Distribution <a class=\"anchor\" id=\"3-severity\"></a>\n",
    "[back to Table of Contents](#toc)\n",
    "\n",
    "Now, we fit a GLM model for the severity with the same features as the freq model.\n",
    "The severity $y$ is the average claim size.\n",
    "We define:\n",
    "- $z$: total claim amount, single claims cut at 100,000\n",
    "- $w$: number of claims (with positive claim amount!)\n",
    "- $y = \\frac{z}{w}$: severity\n",
    "\n",
    "### 3.1 Why Gamma distributions\n",
    "The severity $y$ is a positive, real number, $y \\in (0, \\infty)$. Theoretically, especially for liability claims, one could have arbitrary large numbers&mdash;very unlikely but possible. A very simple distribution for this range is an Exponential distribution, or its generalization, a Gamma distribution $y \\sim Gamma$. In the insurance industry, it is well known that the severity might be skewed and have heavy tails, i.e. a few very large losses, as does our dataset. That's why we only analyse the claim amount cut at 100'000.\n",
    "\n",
    "A Gamma distribution has mean-variance relation $\\mathrm{Var}[Y] = \\frac{\\phi}{w} \\mathrm{E}[Y]^2$. Note that the dispersion $\\phi$ does not influence the estimation of $E[\\mu]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = (\n",
    "    df.loc[:, ['ClaimAmountCut', 'ClaimNb_pos']]\n",
    "    .query('ClaimNb_pos > 0')\n",
    "    .assign(Severity_Observed = lambda x: x['ClaimAmountCut'] / df['ClaimNb_pos'])\n",
    ")\n",
    "\n",
    "df_plot['Severity_Observed'].plot.hist(bins=400, density=True, label='Observed', )\n",
    "\n",
    "x = np.linspace(0, 1e5, num=400)\n",
    "plt.plot(x,\n",
    "         scipy.stats.gamma.pdf(x, *scipy.stats.gamma.fit(df_plot['Severity_Observed'], floc=0)),\n",
    "         'r-', label='fitted Gamma')\n",
    "plt.legend()\n",
    "plt.title(\"Severity\");\n",
    "plt.xlim(left=0, right = 1e4);\n",
    "#plt.xticks(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mean-variance relationship for Gamma: Var[Y] = E[Y]^2 / Exposure\n",
    "# Estimate Var[Y] and E[Y]\n",
    "# Plot estimates Var[Y] vs E[Y]^s/Exposure\n",
    "# Note: We group by VehPower and BonusMalus in order to have different E[Y].\n",
    "\n",
    "def my_agg(x):\n",
    "    \"\"\"See https://stackoverflow.com/q/44635626\"\"\"\n",
    "    x_sev = x['Sev']\n",
    "    x_cnb = x['ClaimNb_pos']\n",
    "    n = x_sev.shape[0]\n",
    "    names = {\n",
    "        'Sev_mean': np.average(x_sev, weights=x_cnb),\n",
    "        'Sev_var': 1/(n-1) * np.sum((x_cnb/np.sum(x_cnb)) * (x_sev-np.average(x_sev, weights=x_cnb))**2),\n",
    "        'ClaimNb_pos_sum': x_cnb.sum()\n",
    "    }\n",
    "    return pd.Series(names, index=['Sev_mean', 'Sev_var', 'ClaimNb_pos_sum'])\n",
    "\n",
    "for col in ['VehPower', 'BonusMalus']:\n",
    "    claims = df.groupby(col)['ClaimNb_pos'].sum()\n",
    "    df_plot = (df.loc[df[col].isin(claims[claims >= 4].index), :]\n",
    "               .query('ClaimNb_pos > 0')\n",
    "               .assign(Sev = lambda x: x['ClaimAmountCut']/x['ClaimNb_pos'])\n",
    "               .groupby(col)\n",
    "               .apply(my_agg)\n",
    "              )\n",
    "\n",
    "    plt.plot(df_plot['Sev_mean'], df_plot['Sev_var'] * df_plot['ClaimNb_pos_sum'], '.',\n",
    "             markersize=12, label='observed')\n",
    "\n",
    "    # fit: mean**p/claims\n",
    "    p = optimize.curve_fit(lambda x, p: np.power(x, p),\n",
    "                           df_plot['Sev_mean'].values,\n",
    "                           df_plot['Sev_var'] * df_plot['ClaimNb_pos_sum'],\n",
    "                           p0 = [2])[0][0]\n",
    "    df_fit = pd.DataFrame({'x': df_plot['Sev_mean'],\n",
    "                           'y': np.power(df_plot['Sev_mean'], p)})\n",
    "    df_fit = df_fit.sort_values('x')\n",
    "\n",
    "    plt.plot(df_fit.x, df_fit.y,\n",
    "             'k--', label='fit: Mean**{}'.format(p))\n",
    "    plt.xlabel('Mean of Severity ')\n",
    "    plt.ylabel('Variance of Severity * ClaimNb_pos')\n",
    "    plt.legend()\n",
    "    plt.title('Man-Variance of Claim Severity by {}'.format(col))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good empirical confirmation to use the Gamma.\n",
    "\n",
    "*Note*: The data seems to be slightly heavier tailed than a Gamma, because estimated p > 2 (it is 2.27 or 2.20). The second plot with BonusMalus might even suggest 2 different regions, on region from 0 to 1'800 and another from 1'800 upwards.\n",
    "\n",
    "*Hint*: If Y were normal distributed, one should see a horizontal line, because $Var[Y] \\sim constant/Exposure$\n",
    "       and the fit should give $p \\approx 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Severity GLM with Train and Test Data\n",
    "We fit a GLM model for the severity with the same features as the freq model. We use the same categorizer as before. \n",
    "\n",
    "*Note*:\n",
    "- We filter out ClaimAmount == 0 as the Gamma distribution as support on $(0, \\infty)$ not $[0, \\infty)$\n",
    "- We use ClaimNb_pos as sample weights.\n",
    "- We use the same split in train and test data such that we can predict the final claim amount on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df['ClaimAmountCut'].values > 0\n",
    "\n",
    "z = df['ClaimAmountCut'].values\n",
    "weight = df['ClaimNb_pos'].values\n",
    "# y = claims severity\n",
    "y = np.zeros_like(z)  # zeros will never be used\n",
    "y[idx] = z[idx] / weight[idx]\n",
    "\n",
    "# we also need to represent train and test as boolean indices\n",
    "itrain = np.zeros(y.shape, dtype='bool')\n",
    "itest = np.zeros(y.shape, dtype='bool')\n",
    "itrain[train] = True\n",
    "itest[test] = True\n",
    "# simplify life\n",
    "itrain = idx & itrain\n",
    "itest = idx & itest\n",
    "\n",
    "X_train_g = glm_categorizer.fit_transform(df[predictors].iloc[itrain])\n",
    "X_test_g = glm_categorizer.fit_transform(df[predictors].iloc[itest])\n",
    "y_train_g, y_test_g = y[itrain], y[itest] \n",
    "w_train_g, w_test_g = weight[itrain], weight[itest]\n",
    "z_train_g, z_test_g = z[itrain], z[itest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit our model with the same parameters before, but of course, this time we use `family=gamma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_glm1 = GeneralizedLinearRegressor(family='gamma', alpha_search=True, l1_ratio=1, fit_intercept=True)\n",
    "s_glm1.fit(X_train_g, y_train_g, sample_weight=weight[itrain])\n",
    "\n",
    "pd.DataFrame({'coefficient': np.concatenate(([s_glm1.intercept_], s_glm1.coef_))},\n",
    "             index=['intercept'] + s_glm1.feature_names_).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we measure peformance with the deviance of the distribution.\n",
    "\n",
    "*Note*: a Gamma distribution is equivlane to a Tweedie distribution with power = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GammaDist = TweedieDistribution(2)\n",
    "print('training loss s_glm1: {}'.format(\n",
    "    GammaDist.deviance(y_train_g, s_glm1.predict(X_train_g), weights=w_train_g)/np.sum(w_train_g)))\n",
    "\n",
    "print('testing loss s_glm1:  {}'.format(\n",
    "    GammaDist.deviance(y_test_g, s_glm1.predict(X_test_g), weights=w_test_g)/np.sum(w_test_g)))\n",
    "\n",
    "print('testing loss Mean:    {}'.format(\n",
    "    GammaDist.deviance(y_test_g,\n",
    "                   np.average(z_train_g, weights=w_train_g)*np.ones_like(z_test_g),\n",
    "                   weights=w_test_g)/np.sum(w_test_g)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Combined Frequency and Severity Results\n",
    "\n",
    "We put together the prediction of frequency and severity to get the predictions of the total claim amount per policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put together freq * sev together\n",
    "print(\"Total claim amount on train set, observed = {}, predicted = {}\".\n",
    "     format(df['ClaimAmountCut'].values[train].sum(),\n",
    "            np.sum(df['Exposure'].values[train] * f_glm1.predict(X_train_p) * s_glm1.predict(X_train_p)))\n",
    "     )\n",
    "\n",
    "print(\"Total claim amount on test set, observed = {}, predicted = {}\".\n",
    "     format(df['ClaimAmountCut'].values[test].sum(),\n",
    "            np.sum(df['Exposure'].values[test] * f_glm1.predict(X_test_p) * s_glm1.predict(X_test_p)))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combined GLM - Tweedie Distribution <a class=\"anchor\" id=\"4-combined\"></a>\n",
    "[back to Table of Contents](#toc)\n",
    "\n",
    "Finally, to demonstrate an alternate approach to the combined frequency severity model, we show how we can model pure premium directly using a Tweedie regressor. Any Tweedie distribution with power $p\\in(1,2)$ is known as [compound Poisson Gamma distribution](https://en.wikipedia.org/wiki/Compound_Poisson_distribution#Compound_Poisson_Gamma_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = df['Exposure'].values\n",
    "df[\"PurePremium\"] = df[\"ClaimAmountCut\"] / df[\"Exposure\"]\n",
    "y = df[\"PurePremium\"]\n",
    "\n",
    "X_train_t = glm_categorizer.fit_transform(df[predictors].iloc[train])\n",
    "X_test_t = glm_categorizer.fit_transform(df[predictors].iloc[test])\n",
    "y_train_t, y_test_t = y.iloc[train], y.iloc[test] \n",
    "w_train_t, w_test_t = weight[train], weight[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we really wanted to optimize the model, we would ideally select the power parameter with a grid-search that minimizes the negative log-likelihood of the Tweedie model. However, for now, we just arbitrarily select 1.5 as our power.\n",
    "\n",
    "*Note*: notice how we pass the distibution in directly for the family parameter. While `quantcore.glm` supports strings for the family parameter, if you are using a common distribution (e.g. like Poisson and Gamma seen above), you can also pass in a quantcore.glm distribution directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TweedieDist = TweedieDistribution(1.5)\n",
    "t_glm1 = GeneralizedLinearRegressor(family=TweedieDist, alpha_search=True, l1_ratio=1, fit_intercept=True)\n",
    "t_glm1.fit(X_train_t, y_train_t, sample_weight=w_train_t)\n",
    "\n",
    "\n",
    "pd.DataFrame({'coefficient': np.concatenate(([t_glm1.intercept_], t_glm1.coef_))},\n",
    "             index=['intercept'] + t_glm1.feature_names_).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we use the distribution's deviance to measure model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training loss s_glm1: {}'.format(\n",
    "    TweedieDist.deviance(y_train_t, t_glm1.predict(X_train_t), weights=w_train_t)/np.sum(w_train_t)))\n",
    "\n",
    "print('testing loss s_glm1:  {}'.format(\n",
    "    TweedieDist.deviance(y_test_t, t_glm1.predict(X_test_t), weights=w_test_t)/np.sum(w_test_t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we again show the total predicted vs. true claim amount on the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put together freq * sev together\n",
    "print(\"Total claim amount on train set, observed = {}, predicted = {}\".\n",
    "     format(df['ClaimAmountCut'].values[train].sum(),\n",
    "            np.sum(df['Exposure'].values[train] * t_glm1.predict(X_train_p)))\n",
    "     )\n",
    "\n",
    "print(\"Total claim amount on test set, observed = {}, predicted = {}\".\n",
    "     format(df['ClaimAmountCut'].values[test].sum(),\n",
    "            np.sum(df['Exposure'].values[test] * t_glm1.predict(X_test_p)))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, the combined frequency severity model performed a bit better, but both approaches prove to be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
