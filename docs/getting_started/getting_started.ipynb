{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Getting Started: fitting a Lasso model \n",
    "\n",
    "Welcome to `quantcore.glm`! Generalized linear models (GLMs) are core statistical tools that include many common methods like least-squares regression, Poisson regression, and logistic regression as special cases. At QuantCo, we have developed `quantcore.glm`, a fast Python-first GLM library. \n",
    "\n",
    "The purpose of this tutorial is to show the basics of `quantcore.glm`. It assumes a working knowledge of python, regularized linear models, and machine learning. The API is very similar to sklearn. After all, `quantcore.glm` is based on a fork of scikit-learn.\n",
    "\n",
    "If you have not done so already, please refer to our [installation instructions](../install.rst) for installing `quantcore.glm`.\n",
    "\n",
    "*Note:* We use the [sklearn boston housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) throughout the tutorial. If you wish to explore this dataset further, there are a handful of resources online. For example, [this blog](https://medium.com/@amitg0161/sklearn-linear-regression-tutorial-with-boston-house-dataset-cde74afd460a). "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from quantcore.glm import GeneralizedLinearRegressor, GeneralizedLinearRegressorCV"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data\n",
    "\n",
    "We start by loading the scikit-learn Boston housing dataset and splitting it into training and test sets. For simplicity, we don't go into any details regarding exploration or data cleaning."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "boston = sklearn.datasets.load_boston()\n",
    "df_bos = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df_bos[\"PRICE\"] = boston.target\n",
    "df_bos = df_bos[df_bos[\"PRICE\"] <= 40]  # remove outliers\n",
    "df_bos.head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "X = df_bos[[\"CRIM\", \"ZN\", \"CHAS\", \"NOX\", \"RM\", \"AGE\", \"TAX\", \"B\", \"LSTAT\"]]\n",
    "y = df_bos[\"PRICE\"]\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.1, random_state=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GLM basics: fitting and predicting using the normal family\n",
    "\n",
    "We'll use `quantcore.glm.GeneralizedLinearRegressor` to predict the house prices using the available predictors. \n",
    "\n",
    "We set three key parameters:\n",
    "\n",
    "- `family`: the family parameter specifies the distributional assumption of the GLM and, as a consequence, the loss function to be minimized. Accepted strings are 'normal', 'poisson', 'gamma', 'inverse.gaussian', and 'binomial'. You can also pass in an instantiated `quantcore.glm` distribution (e.g. `quantcore.glm.TweedieDistribution(1.5)` )\n",
    "- `alpha`: the constant multiplying the penalty term that determines regularization strength. (*Note*: `GeneralizedLinearRegressor` also has an alpha-search option. See the `GeneralizedLinearRegressorCV` example below for details on how alpha-search works).\n",
    "- `l1_ratio`: the elastic net mixing parameter (`0 <= l1_ratio <= 1`). For `l1_ratio = 0`, the penalty is the L2 penalty (ridge). ``For l1_ratio = 1``, it is an L1 penalty (lasso).  For ``0 < l1_ratio < 1``, the penalty is a combination of L1 and L2.\n",
    "\n",
    "To be precise, we will be minimizing the function with respect to the parameters, $\\beta$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{N}(\\mathbf{X}\\beta - y)^2 + \\alpha\\|\\beta\\|_1\n",
    "\\end{equation}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "glm = GeneralizedLinearRegressor(family=\"normal\", alpha=0.1, l1_ratio=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `GeneralizedLinearRegressor.fit()` method follows typical sklearn API style and accepts two primary inputs:\n",
    "\n",
    "1. `X`: the design matrix with shape `(n_samples, n_features)`.\n",
    "2. `y`: the `n_sample` length array of target data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "glm.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GeneralizedLinearRegressor(alpha=0.1, l1_ratio=1)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `predict()` method is also similar to sklearn. It accepts an `(n_samples, n_feature)` shaped design matrix as its input"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(f\"Train RMSE: {sklearn.metrics.mean_squared_error(glm.predict(X_train), y_train, squared=False)}\")\n",
    "print(f\"Test  RMSE: {sklearn.metrics.mean_squared_error(glm.predict(X_test), y_test, squared=False)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train RMSE: 3.8214642780618853\n",
      "Test  RMSE: 2.8768264195444644\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fitting a GLM with cross validation\n",
    "\n",
    "Now, we fit using automatic cross validation with `quantcore.glm.GeneralizedLinearRegressorCV`. This mirrors the commonly used `cv.glmnet` function. \n",
    "\n",
    "Some important parameters:\n",
    "\n",
    "- `alphas`: for `GeneralizedLinearRegressorCV`, the best `alpha` will be found by searching along the regularization path. The regularization path is determined as follows:\n",
    "    1. If `alpha` is an iterable, use it directly. All other parameters\n",
    "        governing the regularization path are ignored.\n",
    "    2. If `min_alpha` is set, create a path from `min_alpha` to the\n",
    "        lowest alpha such that all coefficients are zero.\n",
    "    3. If `min_alpha_ratio` is set, create a path where the ratio of\n",
    "        `min_alpha / max_alpha = min_alpha_ratio`.\n",
    "    4. If none of the above parameters are set, use a `min_alpha_ratio`\n",
    "        of 1e-6.      \n",
    "- `l1_ratio`: for `GeneralizedLinearRegressorCV`, if you pass `l1_ratio` as an array, the `fit` method will choose the best value of `l1_ratio` and store it as `self.l1_ratio_`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "glmcv = GeneralizedLinearRegressorCV(\n",
    "    family=\"normal\",\n",
    "    alphas=None,  # default\n",
    "    min_alpha=None,  # default\n",
    "    min_alpha_ratio=None,  # default\n",
    "    l1_ratio=[0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    fit_intercept=True,\n",
    "    max_iter=150\n",
    ")\n",
    "glmcv.fit(X_train, y_train)\n",
    "print(f\"Chosen alpha:    {glmcv.alpha_}\")\n",
    "print(f\"Chosen l1 ratio: {glmcv.l1_ratio_}\")\n",
    "\n",
    "print(f\"Train RMSE: {sklearn.metrics.mean_squared_error(glmcv.predict(X_train), y_train, squared=False)}\")\n",
    "print(f\"Test  RMSE: {sklearn.metrics.mean_squared_error(glmcv.predict(X_test), y_test, squared=False)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Chosen alpha:    0.021157592673796407\n",
      "Chosen l1 ratio: 0.4\n",
      "Train RMSE: 3.8043984268543487\n",
      "Test  RMSE: 2.8062480574512425\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Congratulations! You have finished our getting started tutorial. If you wish to learn more, please see our other tutorials for more advanced topics like Poisson, Gamma, and Tweedie regression, high dimensional fixed effects, and spatial smoothing using Tikhonov regularization."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}