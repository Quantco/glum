{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are we talking about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A generalized linear model (GLM) is a linear model ($\\eta = x^\\top \\beta$) wrapped in a transformation (link function) and equipped with a response distribution from an exponential family. The choice of link function and response distribution is very flexible. In a GLM, a predictive distribution for the response variable $Y$ is associated with a vector of observed predictors $x$.  The distribution has the form:\n",
    "\n",
    "\\begin{align*}\n",
    "  p(y \\, |\\, x)\n",
    "&=\n",
    "  m(y, \\phi) \\exp\\left(\\frac{\\theta\\, T(y) - A(\\theta)}{\\phi}\\right)\n",
    "\\\\\n",
    "  \\theta\n",
    "&:=\n",
    "  h(\\eta)\n",
    "\\\\\n",
    "  \\eta\n",
    "&:=\n",
    "  x^\\top \\beta\n",
    "\\end{align*}\n",
    "\n",
    "Here $\\beta$ are the parameters, $\\phi$ a parameter representing dispersion (\"variance\"), and $m$, $h$, $T$, $A$ are characterized by the user-specified model family.\n",
    "\n",
    "The mean of $Y$ depends on $x$ by composition of **linear response** $\\eta$ and (inverse) link function, i.e.:\n",
    "\n",
    "$$\n",
    "\\mu := g^{-1}(\\eta)\n",
    "$$\n",
    "\n",
    "where $g$ is the so-called **link function**.  \n",
    "\n",
    "We usually work with a Tweedie distribution, which is a generalization of Poisson ($p=1$) and Gamma ($p=2$):\n",
    "\n",
    "\\begin{align*}\n",
    "\\theta &= \\left\\{\\begin{array}{ll}\n",
    "\\frac{\\mu^{1-p}}{1-p} & \\text{if } p \\neq 1\\\\\n",
    "\\log \\mu              & \\text{if } p = 1\n",
    "\\end{array}\\right.,\\\\\n",
    "T(y) &= y, \\\\\n",
    "A(\\theta) &= \\left\\{\\begin{array}{ll}\n",
    "\\frac{\\mu^{2-p}}{2-p} & \\text{if } p \\neq 2\\\\\n",
    "\\log \\mu              & \\text{if } p = 2.\n",
    "\\end{array}\\right.,\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a GLM, we minimize the negative log-likelihood (or typically the unit deviance) subject to an elastic net constraint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\min_{\\beta} \\mathcal L + \\alpha \\rho ||\\beta||_1  + \\frac{\\alpha (1-\\rho)}{2} ||\\beta||_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With no Lasso constraint (i.e. $\\rho=1$), these problems are usually estimated using Iteratively Reweighted Least Squares (IRLS). With Lasso constraint, some version of coordinate descent is used for the optimization. Other optimization approaches exist (e.g. cvxpy), but we haven't seen these used in large-scale applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our use case in insurance, the critial features for GLMs to be useful for us are\n",
    "- Need to support Gamma, Poisson\n",
    "- Need to support sample weights \n",
    "- Need to support offsets (an offset is a variable for which we force the parameter to equal 1)\n",
    "- Need to work on large-ish data sets (25 million rows, up to several hundred columns)\n",
    "- Can deal with high-dimensional categorical variables (either through sparse matrices or a dedicated solution)\n",
    "- Need to be otherwise sensible (e.g. do not regularize the intercept, etc)\n",
    "- Decent performance in terms of CPU and memory (commercial competitor without regularization needs a couple of minutes on laptop)\n",
    "- Reliably convergent algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nice to have features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Support Tweedie\n",
    "- Ability to specify custom weights for parameters for the L1 penalty\n",
    "- Ability to specify custom weight matrix for parameters for the L2 penalty (generalized Tikhonov regularization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which packages/implementations exist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- glmnet (R-Package, Fortran implementation, GPL-2, no Tweedie, no gamma)\n",
    "https://glmnet.stanford.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pyglmnet (python only, no support of sample weights, no Tweedie, otherwise looks fairly feature-rich, under active development) https://github.com/glm-tools/pyglmnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- python-glmnet (python bindings to glmnet's Fortran code, not actively developed) https://github.com/civisanalytics/python-glmnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- glmnet_python (used at wayfair, GPL licensed) https://github.com/bbalasub1/glmnet_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn fork (python only, has all the features we want, poor performance with sparse matrices, convergence trouble with lasso) https://github.com/scikit-learn/scikit-learn/pull/9405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- scikit-learn master (python only, only ridge, poor performnce with sparse matrices) https://github.com/scikit-learn/scikit-learn/pull/14300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- h2o (Java, python bindings, data needs to be copied from Python to Java all the time, convergence problems) http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tensorflow Probability (C++, python bindings, no sample weights for Lasso) https://www.tensorflow.org/probability/api_docs/python/tfp/glm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- statsmodels (python only, very poor performance, lots of issues getting it to work) https://www.statsmodels.org/stable/glm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other potentially useful reading material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Tensorflow GLM Tutorial](https://colab.research.google.com/github/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Generalized_Linear_Models.ipynb)\n",
    "- [Sklearn User guide](https://scikit-learn.org/dev/modules/linear_model.html#generalized-linear-regression)\n",
    "- [Tutorial on Insurance Claims Modelling with sklearn](https://github.com/lorentzenchr/Tutorial_freMTPL2/blob/master/glm_freMTPL2_example.ipynb)\n",
    "- [pyglmnet Tutorial](http://glm-tools.github.io/pyglmnet/tutorial.html)\n",
    "- [Improved GLMNET](https://www.csie.ntu.edu.tw/~cjlin/papers/l1_glmnet/long-glmnet.pdf)\n",
    "- [h2o Documentation on GLMs (fairly extensive)](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/glm.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
