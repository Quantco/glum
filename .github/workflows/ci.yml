name: CI
on:
  # We would like to trigger for CI for any pull request action -
  # both from QuantCo's branches as well as forks.
  pull_request:
  # In addition to pull requests, we want to run CI for pushes
  # to the main branch and tags.
  push:
    branches:
      - "main"
    tags:
      - "*"

jobs:
  pre-commit-checks:
    name: Linux - pre-commit checks
    timeout-minutes: 30
    runs-on: ubuntu-latest
    env:
      PRE_COMMIT_USE_MICROMAMBA: 1
    steps:
      - name: Checkout branch
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
      - name: Set up pixi
        uses: prefix-dev/setup-pixi@a0af7a228712d6121d37aba47adf55c1332c9c2e # v0.9.4
        with:
          environments: lint default
      - name: pre-commit
        run: pixi run -e lint pre-commit-run --color=always --show-diff-on-failure

  unit-tests:
    name: Tests
    runs-on: ${{ matrix.os }}
    env:
      CI: True
    strategy:
      fail-fast: true
      matrix:
        include:
          - { os: ubuntu-latest, environment: 'py310' }
          - { os: ubuntu-latest, environment: 'py311' }
          - { os: ubuntu-latest, environment: 'py312' }
          - { os: ubuntu-latest, environment: 'py313' }
          - { os: windows-latest, environment: 'py313' }
          - { os: macos-latest, environment: 'py313' }
          - { os: ubuntu-latest, environment: 'oldies' }
          - { os: ubuntu-latest, environment: 'nightly' }
    steps:
      - name: Checkout branch
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
      - name: Set up pixi
        uses: prefix-dev/setup-pixi@a0af7a228712d6121d37aba47adf55c1332c9c2e
        with:
          environments: ${{ matrix.environment }}
      - name: Update dependencies
        if: matrix.environment == 'nightly'
        run: pixi update -e ${{ matrix.environment }}
      - name: Install nightlies
        if: matrix.environment == 'nightly'
        run: pixi run -e ${{ matrix.environment }} install-nightlies
      - name: Install repository
        run: pixi run -e ${{ matrix.environment }} postinstall
      - name: Run pytest
        run: pixi run -e ${{ matrix.environment }} test -nauto
      - name: Run doctest
        # Check that the readme example will work by running via doctest.
        # We run outside the repo to make the test a bit more similar to
        # a user running after installing with conda.
        run: |
          mkdir ../temp
          cp README.md ../temp
          mkdir ../temp/data
          cp data/housing.parquet ../temp/data
          cd ../temp
          pixi run --manifest-path ../glum/pixi.toml -e ${{ matrix.environment }} python -m doctest -v README.md

  runtime-regression:
    name: Runtime regression (PR)
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    timeout-minutes: 10
    env:
      BASE_SHA: ${{ github.event.pull_request.base.sha }}
      HEAD_SHA: ${{ github.sha }}
      OMP_NUM_THREADS: "1"
      MKL_NUM_THREADS: "1"
      OPENBLAS_NUM_THREADS: "1"
      NUMEXPR_NUM_THREADS: "1"
      PYTHONHASHSEED: "0"
      GLM_BENCHMARKS_RUNTIME_AGGREGATION: "trimmed_mean"
      GLM_BENCHMARKS_RUNTIME_TRIM_RATIO: "0.2"
    steps:
      - name: Checkout branch
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          fetch-depth: 0
      - name: Ensure base commit is available
        run: git fetch --no-tags --prune origin "$BASE_SHA" || true
      - name: Set up pixi
        uses: prefix-dev/setup-pixi@a0af7a228712d6121d37aba47adf55c1332c9c2e
        with:
          environments: benchmark
      - name: Run benchmarks (base vs head) and compare
        shell: bash
        run: |
          set -euo pipefail

          ROOT="$PWD"
          mkdir -p "$ROOT/glum_benchmarks/results"
          BASE_WT="$(mktemp -d /tmp/glum-base-XXXXXX)"
          HEAD_WT="$(mktemp -d /tmp/glum-head-XXXXXX)"

          cleanup() {
            git worktree remove --force "$BASE_WT" >/dev/null 2>&1 || true
            git worktree remove --force "$HEAD_WT" >/dev/null 2>&1 || true
            rm -rf "$BASE_WT" "$HEAD_WT" >/dev/null 2>&1 || true
          }
          trap cleanup EXIT

          git worktree add --detach "$BASE_WT" "$BASE_SHA"
          git worktree add --detach "$HEAD_WT" "$HEAD_SHA"

          run_ref () {
            local wt="$1"
            local run_name="$2"
            local warmup_run_name="warmup-${run_name}"
            local cache_dir="$ROOT/glum_benchmarks/results/cache-${run_name}"
            cd "$wt"
            pixi run -e benchmark python -m pip install \
              --no-build-isolation --no-deps --disable-pip-version-check \
              -e .

            # Warmup pass (discarded) to reduce first-run bias without changing benchmark logic.
            GLM_BENCHMARKS_CACHE="$cache_dir" PYTHONPATH="$ROOT" pixi run -e benchmark python "$ROOT/glum_benchmarks/run_benchmarks.py" \
              --config "$ROOT/glum_benchmarks/config_ci.yaml" \
              --run-name "$warmup_run_name"
            rm -rf "$ROOT/glum_benchmarks/results/$warmup_run_name"

            # Measured pass
            GLM_BENCHMARKS_CACHE="$cache_dir" PYTHONPATH="$ROOT" pixi run -e benchmark python "$ROOT/glum_benchmarks/run_benchmarks.py" \
              --config "$ROOT/glum_benchmarks/config_ci.yaml" \
              --run-name "$run_name"
          }

          run_ref "$BASE_WT" "ci-base"
          run_ref "$HEAD_WT" "ci-head"

          cd "$ROOT"
          PYTHONPATH="$ROOT" pixi run -e benchmark python glum_benchmarks/compare_results.py \
            --base glum_benchmarks/results/ci-base/results.csv \
            --head glum_benchmarks/results/ci-head/results.csv \
            --config glum_benchmarks/config_ci.yaml \
            --summary-out glum_benchmarks/results/ci_runtime_summary.md
      - name: Publish summary
        if: always()
        run: |
          echo "## Runtime regression summary" >> "$GITHUB_STEP_SUMMARY"
          if [ -f glum_benchmarks/results/ci_runtime_summary.md ]; then
            cat glum_benchmarks/results/ci_runtime_summary.md >> "$GITHUB_STEP_SUMMARY"
          else
            echo "_No summary produced (benchmark step failed early)_" >> "$GITHUB_STEP_SUMMARY"
          fi
      - name: Upload runtime artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-runtime-regression
          if-no-files-found: warn
          path: |
            glum_benchmarks/results/ci_runtime_summary.md
            glum_benchmarks/results/ci-base/**/*
            glum_benchmarks/results/ci-head/**/*
